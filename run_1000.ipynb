{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Milla-Val et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(\"README.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:41:55.068645Z",
     "iopub.status.busy": "2023-09-01T01:41:55.068419Z",
     "iopub.status.idle": "2023-09-01T01:41:57.611306Z",
     "shell.execute_reply": "2023-09-01T01:41:57.610572Z"
    },
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:41:55.068645Z",
     "iopub.status.busy": "2023-09-01T01:41:55.068419Z",
     "iopub.status.idle": "2023-09-01T01:41:57.611306Z",
     "shell.execute_reply": "2023-09-01T01:41:57.610572Z"
    },
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "# Set memory growth for the GPU to reduce excesice VRAM utilization\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "# Create, if it not exists, a folder\n",
    "def creaCarpeta(ruta_save_fig='/folder/folder2'):\n",
    "    try: \n",
    "        os.makedirs(ruta_save_fig)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(ruta_save_fig):\n",
    "            raise\n",
    "    return ruta_save_fig+\"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths for data inputs, logs, checkpoints and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the input data\n",
    "data_folder = '/home/jmilla/DoctoradoData/piri10h_datasets/dataPiri1h_resMean.npz'\n",
    "\n",
    "# Path for the checkpoint directory. \n",
    "# Pointing this to a ramdisk speed-up training.\n",
    "checkpoint_dir = '/home/jmilla/ramdisk/pix2pix_own_ckpt'\n",
    "\n",
    "# Path for the logs files\n",
    "log_dir = \"logs/\"\n",
    "\n",
    "# Path for results. 'creaCarpeta' will create a new folder with the specified name\n",
    "res_dir = creaCarpeta('./results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compNUM = 2\n",
    "\n",
    "data = np.load(data_folder)\n",
    "\n",
    "#([Ux(0), Uy(1), Uz(2), u(3), v(4), wa(5)], dates, lat, lon, eta)\n",
    "velTrain = data['velTrain'] \n",
    "velTest = data['velTest']\n",
    "# print(velTrain.shape, velTest.shape)\n",
    "\n",
    "cfdTrain = velTrain[0:compNUM,:,:,:,0:1]\n",
    "cfdTrain = cfdTrain.swapaxes(0,-1)[0]\n",
    "wrfTrain = velTrain[3:(3+compNUM),:,:,:,0:1]\n",
    "wrfTrain = wrfTrain.swapaxes(0,-1)[0]\n",
    "\n",
    "cfdTest = velTest[0:compNUM,:,:,:,0:1]\n",
    "cfdTest = cfdTest.swapaxes(0,-1)[0]\n",
    "wrfTest = velTest[3:(3+compNUM),:,:,:,0:1]\n",
    "wrfTest = wrfTest.swapaxes(0,-1)[0]\n",
    "\n",
    "display.display(('cfdTrain', cfdTrain.shape), (cfdTrain.max((0,1,2)), cfdTrain.min((0,1,2))))\n",
    "display.display(('wrfTrain', wrfTrain.shape), (wrfTrain.max((0,1,2)), wrfTrain.min((0,1,2))))\n",
    "display.display(('cfdTest', cfdTest.shape), (cfdTest.max(), cfdTest.min()))\n",
    "display.display(('wrfTest', wrfTest.shape), (wrfTest.max(), wrfTest.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:14.302384Z",
     "iopub.status.busy": "2023-09-01T01:42:14.302149Z",
     "iopub.status.idle": "2023-09-01T01:42:14.305594Z",
     "shell.execute_reply": "2023-09-01T01:42:14.305005Z"
    },
    "id": "2CbTEt448b4R"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 193\n",
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the images to [-1, 1]\n",
    "def normalize(inp, real):\n",
    "    inp = (inp + 30) / 60\n",
    "    inp = tf.cast(inp*2.0 - 1.0, tf.float32)\n",
    "    \n",
    "    real = (real + 60) / 140\n",
    "    real = tf.cast(real*2.0 - 1.0, tf.float32)\n",
    "\n",
    "    return inp, real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIGN6ouoQxt3"
   },
   "source": [
    "## Build an input pipeline with `tf.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((wrfTrain, cfdTrain))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((wrfTest, cfdTest))\n",
    "\n",
    "train_dataset = train_dataset.map(normalize,\n",
    "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE, seed=1234)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = train_dataset.take(int(len(train_dataset)*0.2))\n",
    "train_dataset = train_dataset.skip(int(len(train_dataset)*0.2))\n",
    "\n",
    "test_dataset = test_dataset.map(normalize,\n",
    "                                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Build the generator\n",
    "\n",
    "The generator of the pix2pix cGAN is a _modified_ [U-Net](https://arxiv.org/abs/1505.04597). A U-Net consists of an encoder (downsampler) and decoder (upsampler). (You can find out more about it in the [U-Net project website](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/).)\n",
    "\n",
    "- Each block in the encoder is: Convolution -> >PReLU\n",
    "- Each block in the decoder is: Transposed convolution -> Dropout (applied to the first 3 blocks) -> ReLU\n",
    "- There are skip connections between the encoder and decoder (as in the U-Net)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MQPuBCgtldI"
   },
   "source": [
    "Define the downsampler (encoder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:15.336264Z",
     "iopub.status.busy": "2023-09-01T01:42:15.336026Z",
     "iopub.status.idle": "2023-09-01T01:42:15.339188Z",
     "shell.execute_reply": "2023-09-01T01:42:15.338544Z"
    },
    "id": "tqqvWxlw8b4l"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = compNUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:15.342139Z",
     "iopub.status.busy": "2023-09-01T01:42:15.341887Z",
     "iopub.status.idle": "2023-09-01T01:42:15.346381Z",
     "shell.execute_reply": "2023-09-01T01:42:15.345767Z"
    },
    "id": "3R09ATE_SH9P"
   },
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "    result.add(tf.keras.layers.PReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFI_Pa52tjLl"
   },
   "source": [
    "Define the upsampler (decoder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:16.152929Z",
     "iopub.status.busy": "2023-09-01T01:42:16.152461Z",
     "iopub.status.idle": "2023-09-01T01:42:16.157335Z",
     "shell.execute_reply": "2023-09-01T01:42:16.156728Z"
    },
    "id": "nhgDsHClSQzP"
   },
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.PReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueEJyRVrtZ-p"
   },
   "source": [
    "Define the generator with the downsampler and the upsampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:16.526913Z",
     "iopub.status.busy": "2023-09-01T01:42:16.526257Z",
     "iopub.status.idle": "2023-09-01T01:42:16.534152Z",
     "shell.execute_reply": "2023-09-01T01:42:16.533550Z"
    },
    "id": "lFPI4Nu-8b4q"
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[128, 128, compNUM])\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 5, apply_batchnorm=False),  # (batch_size, 64, 64, 64)\n",
    "        downsample(128, 5),  # (batch_size, 32, 32, 128)\n",
    "        downsample(256, 5),  # (batch_size, 16, 16, 256)\n",
    "        downsample(512, 5),  # (batch_size, 8, 8, 512)\n",
    "        downsample(512, 5),  # (batch_size, 4, 4, 512)\n",
    "        downsample(512, 5),  # (batch_size, 2, 2, 512)\n",
    "        downsample(512, 5),  # (batch_size, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 5, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
    "        upsample(512, 5, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
    "        upsample(512, 5, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
    "        upsample(512, 5),  # (batch_size, 16, 16, 768)\n",
    "        upsample(256, 5),  # (batch_size, 32, 32, 384)\n",
    "        upsample(128, 5),  # (batch_size, 64, 64, 192)\n",
    "    ]\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 5,\n",
    "                                           strides=2,\n",
    "                                           padding='same',\n",
    "                                           kernel_initializer=initializer,\n",
    "                                           activation='tanh')  # (batch_size, 128, 128, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4PKwrcQFYvF"
   },
   "source": [
    "Visualize the generator model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:16.537186Z",
     "iopub.status.busy": "2023-09-01T01:42:16.536958Z",
     "iopub.status.idle": "2023-09-01T01:42:17.472119Z",
     "shell.execute_reply": "2023-09-01T01:42:17.471071Z"
    },
    "id": "dIbRPFzjmV85"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n",
    "# generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpDPEQXIAiQO"
   },
   "source": [
    "### Define the generator loss\n",
    "\n",
    "GANs learn a loss that adapts to the data, while cGANs learn a structured loss that penalizes a possible structure that differs from the network output and the target image, as described in the [pix2pix paper](https://arxiv.org/abs/1611.07004).\n",
    "\n",
    "- The generator loss is a sigmoid cross-entropy loss of the generated images and an **array of ones**.\n",
    "- The pix2pix paper also mentions the L1 loss, which is a MAE (mean absolute error) between the generated image and the target image.\n",
    "- This allows the generated image to become structurally similar to the target image.\n",
    "- The formula to calculate the total generator loss is `gan_loss + LAMBDA * l1_loss`, where `LAMBDA = 1000`. Original value of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:18.629932Z",
     "iopub.status.busy": "2023-09-01T01:42:18.629635Z",
     "iopub.status.idle": "2023-09-01T01:42:18.632992Z",
     "shell.execute_reply": "2023-09-01T01:42:18.632415Z"
    },
    "id": "cyhxTuvJyIHV"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:18.635844Z",
     "iopub.status.busy": "2023-09-01T01:42:18.635615Z",
     "iopub.status.idle": "2023-09-01T01:42:18.638853Z",
     "shell.execute_reply": "2023-09-01T01:42:18.638281Z"
    },
    "id": "Q1Xbz5OaLj5C"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:18.641895Z",
     "iopub.status.busy": "2023-09-01T01:42:18.641675Z",
     "iopub.status.idle": "2023-09-01T01:42:18.645476Z",
     "shell.execute_reply": "2023-09-01T01:42:18.644909Z"
    },
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # Mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTKZfoaoEF22"
   },
   "source": [
    "## Build the discriminator\n",
    "\n",
    "The discriminator in the pix2pix cGAN is a convolutional PatchGAN classifier—it tries to classify if each image _patch_ is real or not real, as described in the [pix2pix paper](https://arxiv.org/abs/1611.07004).\n",
    "\n",
    "- Each block in the discriminator is: Convolution -> PReLU.\n",
    "- The shape of the output after the last layer is `(batch_size, 7, 7, 1)`.\n",
    "- The discriminator receives 2 inputs: \n",
    "    - The input image and the target image, which it should classify as real.\n",
    "    - The input image and the generated image (the output of the generator), which it should classify as fake.\n",
    "    - Use `tf.concat([inp, tar], axis=-1)` to concatenate these 2 inputs together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIuTeGL5v45m"
   },
   "source": [
    "Let's define the discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:18.649079Z",
     "iopub.status.busy": "2023-09-01T01:42:18.648594Z",
     "iopub.status.idle": "2023-09-01T01:42:18.655015Z",
     "shell.execute_reply": "2023-09-01T01:42:18.654441Z"
    },
    "id": "ll6aNeQx8b4v"
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[128, 128, OUTPUT_CHANNELS], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[128, 128, OUTPUT_CHANNELS], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 128, 128, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 7, False)(x)  # (batch_size, 64, 64, 64)\n",
    "    down2 = downsample(128, 7)(down1)  # (batch_size, 32, 32, 128)\n",
    "    down3 = downsample(256, 7)(down2)  # (batch_size, 16, 16, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 18, 18, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  # (batch_size, 15, 15, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 17, 17, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=2,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 7, 7, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdV9yAbBHNkg"
   },
   "source": [
    "Visualize the discriminator model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:18.657981Z",
     "iopub.status.busy": "2023-09-01T01:42:18.657754Z",
     "iopub.status.idle": "2023-09-01T01:42:18.920142Z",
     "shell.execute_reply": "2023-09-01T01:42:18.919231Z"
    },
    "id": "YHoUui4om-Ev"
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)\n",
    "# discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOqg1dhUAWoD"
   },
   "source": [
    "### Define the discriminator loss\n",
    "\n",
    "- The `discriminator_loss` function takes 2 inputs: **real images** and **generated images**.\n",
    "- `real_loss` is a sigmoid cross-entropy loss of the **real images** and an **array of ones(since these are the real images)**.\n",
    "- `generated_loss` is a sigmoid cross-entropy loss of the **generated images** and an **array of zeros (since these are the fake images)**.\n",
    "- The `total_loss` is the sum of `real_loss` and `generated_loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:19.305844Z",
     "iopub.status.busy": "2023-09-01T01:42:19.305570Z",
     "iopub.status.idle": "2023-09-01T01:42:19.309745Z",
     "shell.execute_reply": "2023-09-01T01:42:19.309064Z"
    },
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Define the optimizers and a checkpoint-saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:19.313435Z",
     "iopub.status.busy": "2023-09-01T01:42:19.312859Z",
     "iopub.status.idle": "2023-09-01T01:42:19.321353Z",
     "shell.execute_reply": "2023-09-01T01:42:19.320772Z"
    },
    "id": "lbHFNexF0x6O"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:19.324747Z",
     "iopub.status.busy": "2023-09-01T01:42:19.324195Z",
     "iopub.status.idle": "2023-09-01T01:42:19.328703Z",
     "shell.execute_reply": "2023-09-01T01:42:19.328074Z"
    },
    "id": "WJnftd5sQsv6"
   },
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Generate images\n",
    "\n",
    "Write a function to plot some images during training.\n",
    "\n",
    "- Pass images from the test set to the generator.\n",
    "- The generator will then translate the input image into the output.\n",
    "- The last step is to plot the predictions and _voila_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rb0QQFHF-JfS"
   },
   "source": [
    "Note: The `training=True` is intentional here since you want the batch statistics, while running the model on the test dataset. If you use `training=False`, you get the accumulated statistics learned from the training dataset (which you don't want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:19.332243Z",
     "iopub.status.busy": "2023-09-01T01:42:19.331810Z",
     "iopub.status.idle": "2023-09-01T01:42:19.336598Z",
     "shell.execute_reply": "2023-09-01T01:42:19.335975Z"
    },
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar, plot=True):\n",
    "    prediction = model(test_input, training=True)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "\n",
    "        display_list = [test_input[0], tar[0], prediction[0]]\n",
    "        title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.title(title[i])\n",
    "\n",
    "            # Getting the pixel values in the [0, 1] range to plot\n",
    "            # and setting the third channel to a constant 0.5\n",
    "            plt.imshow(tf.concat((display_list[i], \n",
    "                                  tf.zeros_like(display_list[i][...,:1])), axis=-1) * 0.5 + 0.5)\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "    return prediction  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLKOG55MErD0"
   },
   "source": [
    "## Training\n",
    "\n",
    "- For each example input generates an output.\n",
    "- The discriminator receives the `input_image` and the generated image as the first input. The second input is the `input_image` and the `target_image`.\n",
    "- Next, calculate the generator and the discriminator loss.\n",
    "- Then, calculate the gradients of loss with respect to both the generator and the discriminator variables(inputs) and apply those to the optimizer.\n",
    "- Finally, log the losses to TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:20.502226Z",
     "iopub.status.busy": "2023-09-01T01:42:20.501889Z",
     "iopub.status.idle": "2023-09-01T01:42:20.507868Z",
     "shell.execute_reply": "2023-09-01T01:42:20.507228Z"
    },
    "id": "xNNMDBNH12q-"
   },
   "outputs": [],
   "source": [
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "current_time = f'lambda_{LAMBDA}'\n",
    "\n",
    "summary_writer_train = tf.summary.create_file_writer(\n",
    "  log_dir + current_time + '/train')\n",
    "summary_writer_val = tf.summary.create_file_writer(\n",
    "  log_dir + current_time + '/validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_step`, `test_step` and `fit` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:20.510872Z",
     "iopub.status.busy": "2023-09-01T01:42:20.510617Z",
     "iopub.status.idle": "2023-09-01T01:42:20.518874Z",
     "shell.execute_reply": "2023-09-01T01:42:20.518208Z"
    },
    "id": "KBKUV2sKXDbY"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target, step):\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    # Gradients\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                            generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                                 discriminator.trainable_variables)\n",
    "    # Apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                            generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                                discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, gen_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:20.510872Z",
     "iopub.status.busy": "2023-09-01T01:42:20.510617Z",
     "iopub.status.idle": "2023-09-01T01:42:20.518874Z",
     "shell.execute_reply": "2023-09-01T01:42:20.518208Z"
    },
    "id": "KBKUV2sKXDbY"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(input_image, target, step):\n",
    "    \n",
    "    gen_output = generator(input_image, training=True)\n",
    "\n",
    "    disc_real_output = discriminator([input_image, target], training=True)\n",
    "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, gen_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:20.522375Z",
     "iopub.status.busy": "2023-09-01T01:42:20.521738Z",
     "iopub.status.idle": "2023-09-01T01:42:20.527347Z",
     "shell.execute_reply": "2023-09-01T01:42:20.526673Z"
    },
    "id": "GFyPlBWv1B5j"
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, test_ds, epochs):\n",
    "    tloss_list = []\n",
    "    dloss_list = []\n",
    "    gloss_list = []\n",
    "    \n",
    "    tlossOLD = 1e10\n",
    "    for example_input, example_target in test_dataset.take(1):\n",
    "        pass\n",
    "    \n",
    "    start = time.time()\n",
    "    display.clear_output(wait=True)\n",
    "    for epoch in tqdm(range(epochs), desc=\"epoch\", position=0):\n",
    "        lr = generator_optimizer.lr.numpy()\n",
    "        \n",
    "        # Traingin for each batch\n",
    "        for step, (input_image, target) in tqdm(train_ds.enumerate(), \n",
    "                                                desc='batch', position=1, leave=False):\n",
    "            gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, gen_total_loss = train_step(input_image, target, step)\n",
    "        \n",
    "        with summary_writer_train.as_default():\n",
    "            tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "            tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "            tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
    "            tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
    "            tf.summary.scalar('TOTAL_loss', gen_total_loss + disc_loss, step=epoch)\n",
    "            tf.summary.scalar('lr', lr, step=epoch)\n",
    "            \n",
    "        tloss_list.append(gen_total_loss + disc_loss)\n",
    "        dloss_list.append(disc_loss)\n",
    "        gloss_list.append(gen_gan_loss)\n",
    "        \n",
    "        # Test loop\n",
    "        for step, (input_image, target) in test_ds.enumerate():\n",
    "            gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, gen_total_loss = test_step(input_image, target, step)\n",
    "\n",
    "        with summary_writer_val.as_default():\n",
    "            tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "            tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "            tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
    "            tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
    "            tf.summary.scalar('TOTAL_loss', gen_total_loss + disc_loss, step=epoch)\n",
    "            \n",
    "        tloss_test = gen_total_loss + disc_loss\n",
    "\n",
    "        if tloss_test<tlossOLD:\n",
    "            old_counter = checkpoint.save_counter.numpy()\n",
    "            checkpoint.save_counter.assign(0)\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            tlossOLD = tloss_test\n",
    "            checkpoint.save_counter.assign(old_counter)\n",
    "        \n",
    "        # Check if the Generator-Discriminator losses have stabilized\n",
    "        if epoch>2:        \n",
    "            fit_curve = tf.concat((tf.concat(tloss_list, axis=0)[...,tf.newaxis], \n",
    "                          tf.concat(gloss_list, axis=0)[...,tf.newaxis], \n",
    "                          tf.concat(dloss_list, axis=0)[...,tf.newaxis]), axis=1)\n",
    "            \n",
    "            df = pd.DataFrame(fit_curve, columns=['Tot', 'G', 'D'])\n",
    "            rolling = df.rolling(300).std()\n",
    "            \n",
    "            if ((rolling.G.iloc[-1]<rolling.G.max()*0.1) |\n",
    "                (rolling.D.iloc[-1]<rolling.D.max()*0.1)):\n",
    "                \n",
    "                print('Early stopping... saving model.')\n",
    "                checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "                break\n",
    "                        \n",
    "    return fit_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe0-8Bzg22ox"
   },
   "source": [
    "Finally, run the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T01:42:20.530843Z",
     "iopub.status.busy": "2023-09-01T01:42:20.530317Z",
     "iopub.status.idle": "2023-09-01T02:42:53.947504Z",
     "shell.execute_reply": "2023-09-01T02:42:53.946609Z"
    },
    "id": "a1zZmKmvOH85",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print('Training...')\n",
    "fit_curve = fit(train_dataset, val_dataset, epochs=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMTm4peo3cem"
   },
   "source": [
    "Interpreting the logs is more subtle when training a GAN (or a cGAN like pix2pix) compared to a simple classification or regression model. Things to look for:\n",
    "\n",
    "- Check that neither the generator nor the discriminator model has \"won\". If either the `gen_gan_loss` or the `disc_loss` gets very low, it's an indicator that this model is dominating the other, and you are not successfully training the combined model.\n",
    "- The value `log(2) = 0.69` is a good reference point for these losses, as it indicates a perplexity of 2 - the discriminator is, on average, equally uncertain about the two options.\n",
    "- For the `disc_loss`, a value below `0.69` means the discriminator is doing better than random on the combined set of real and generated images.\n",
    "- For the `gen_gan_loss`, a value below `0.69` means the generator is doing better than random at fooling the discriminator.\n",
    "- As training progresses, the `gen_l1_loss` should go down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kz80bY3aQ1VZ"
   },
   "source": [
    "## Restore the latest checkpoint and test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T02:42:53.952175Z",
     "iopub.status.busy": "2023-09-01T02:42:53.951560Z",
     "iopub.status.idle": "2023-09-01T02:42:54.149779Z",
     "shell.execute_reply": "2023-09-01T02:42:54.148956Z"
    },
    "id": "HSSm4kfvJiqv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T02:42:54.153279Z",
     "iopub.status.busy": "2023-09-01T02:42:54.153029Z",
     "iopub.status.idle": "2023-09-01T02:42:54.968866Z",
     "shell.execute_reply": "2023-09-01T02:42:54.968140Z"
    },
    "id": "4t4x69adQ5xb"
   },
   "outputs": [],
   "source": [
    "# Restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RGysMU_BZhx"
   },
   "source": [
    "## Generate some images using the `test set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T02:42:54.972615Z",
     "iopub.status.busy": "2023-09-01T02:42:54.972055Z",
     "iopub.status.idle": "2023-09-01T02:42:57.067436Z",
     "shell.execute_reply": "2023-09-01T02:42:57.066444Z"
    },
    "id": "KUgSnmy2nqSP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the trained model on a few examples from the test set\n",
    "norm = colors.Normalize(vmin=-60, vmax=80)\n",
    "\n",
    "pred_list = []\n",
    "\n",
    "for inp, tar in test_dataset:\n",
    "    pred = generate_images(generator, inp, tar, plot=False)\n",
    "    pred01 = (pred.numpy()*0.5+0.5)\n",
    "    tar01 = (tar.numpy()*0.5+0.5)\n",
    "    \n",
    "    try:\n",
    "        pred_list = np.concatenate((pred_list, norm.inverse(pred01)))\n",
    "    except ValueError:\n",
    "        pred_list = norm.inverse(pred01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RGysMU_BZhx"
   },
   "source": [
    "## Generate some images using the `train set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T02:42:54.972615Z",
     "iopub.status.busy": "2023-09-01T02:42:54.972055Z",
     "iopub.status.idle": "2023-09-01T02:42:57.067436Z",
     "shell.execute_reply": "2023-09-01T02:42:57.066444Z"
    },
    "id": "KUgSnmy2nqSP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the trained model on a few examples from the train set\n",
    "norm = colors.Normalize(vmin=-60, vmax=80)\n",
    "\n",
    "train_list = []\n",
    "\n",
    "for inp, tar in train_dataset:\n",
    "    pred = generate_images(generator, inp, tar, plot=False)\n",
    "    pred01 = (pred.numpy()*0.5+0.5)\n",
    "    tar01 = (tar.numpy()*0.5+0.5)\n",
    "    \n",
    "    try:\n",
    "        train_list = np.concatenate((train_list, norm.inverse(pred01)))\n",
    "    except ValueError:\n",
    "        train_list = norm.inverse(pred01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(res_dir+f'lambda{LAMBDA}', \n",
    "                    train=train_list[...,:OUTPUT_CHANNELS], \n",
    "                    test=pred_list[...,:OUTPUT_CHANNELS], \n",
    "                    loss=np.array([np.nan]), #legacy for analysis script, not relevant\n",
    "                    val_loss=np.array([np.nan]), #legacy for analysis script, not relevant\n",
    "                    hist=None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pix2pix.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.8]",
   "language": "python",
   "name": "conda-env-tf-2.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
